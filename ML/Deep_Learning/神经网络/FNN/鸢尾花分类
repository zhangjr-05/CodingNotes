import os
import sys
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader


class iris_dataloader(Dataset):
    def __init__(self, data_path):
        super().__init__()
        self.data_path = data_path

        assert os.path.exists(self.data_path), "dataset does not exist"

        df = pd.read_csv(self.data_path)

        data = df.iloc[:, :4]
        label = df.iloc[:, 4:]

        data = (data - np.mean(data) / np.std(data))    # Z值化

        self.data = torch.from_numpy(np.array(data, dtype='float32'))
        self.label = torch.from_numpy(np.array(label, dtype='int64'))

        self.data_num = len(label)

    def __len__(self):
        return self.data_num

    def __getitem__(self, index):
        return self.data[index], self.label[index]
    

# 神经网络搭建
class NN(nn.Module):
    def __init__(self, in_dim, hidden_dim1, hidden_dim2, out_dim):
        super().__init__()
        self.layer1 = nn.Linear(in_dim, hidden_dim1)
        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)
        self.layer3 = nn.Linear(hidden_dim2, out_dim)

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

        return x
    
# 定义计算环境
device = torch.device("cuda:0"if torch.cuda.is_available() else "cpu")

# 训练集，验证集，测试集
custom_dataset = iris_dataloader("./files/iris.csv")
train_size = int(len(custom_dataset) * 0.7)
val_size = int(len(custom_dataset) * 0.2)
test_size = len(custom_dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(custom_dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# 定义一个推理函数，来计算并返回准确率
def infer(model, dataset, device):
    model.eval()
    acc_num = 0
    with torch.no_grad():
        for data in dataset:
            datas, labels = data
            outputs = model(datas.to(device))
            predict_y = torch.max(outputs, dim=1)[1]
            acc_num += torch.eq(predict_y, labels.to(device)).sum().item()
    acc = acc_num / len(dataset)
    return acc

def main(lr=0.005, epochs=20):
    model = NN(4, 12, 6, 3).to(device)
    loss_f = nn.CrossEntropyLoss()

    pg = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.Adam(pg, lr=lr)

    # 权重文件储存路径
    save_path = os.path.join(os.getcwd(), "results/weights")
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    # 开始训练
    for epoch in range(epochs):
        model.train()
        acc_num = torch.zeros(1).to(device)
        sample_num = 0

        train_bar = tqdm(train_loader, file=sys.stdout, ncols=100)
        for datas in train_bar:
            data, label = datas
            label = label.squeeze(-1)
            sample_num += data.shape[0]

            optimizer.zero_grad()
            outputs = model(data.to(device))
            pred_class = torch.max(outputs, dim=1)[1]
            acc_num = torch.eq(pred_class, label.to(device)).sum()

            loss = loss_f(outputs, label.to(device))
            loss.backward()
            optimizer.step()

            train_acc = acc_num / sample_num
            train_bar.desc = "train epoch [{}/{}]".format(epoch + 1, epochs)

        val_acc = infer(model, val_loader, device)
        torch.save(model.state_dict(), os.path.join(save_path, "nn.pth"))
        print(f'loss: {loss:.3f}  train_acc:  {train_acc:.3f}  val_acc: {val_acc:.3f}\n')
        # 每次数据集迭代之后对初始化的指标清零
        train_acc = 0
        val_acc = 0

    test_acc = infer(model, test_loader, device)
    print("Train finished, test_acc:", test_acc, '\n')

if __name__ == "__main__":
    main()
    