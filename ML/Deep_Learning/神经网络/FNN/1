# pytorch第一个神经网络
import torch
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 定义输入层，隐藏层，输出层和批量的大小
n_in, n_h, n_out, batch_size = 10, 5, 1, 10

# 创建虚拟输入数据和目标数据
x = torch.randn(batch_size, n_in).to(device)
y = torch.randint(0, 2, (batch_size, n_out)).float().to(device)

# 定义神经网络模型
model = nn.Sequential(
    nn.Linear(n_in, n_h),   # 输入层到隐藏层的线性变换
    nn.ReLU(),                # 隐藏层的ReLU激活函数，增加非线性
    nn.Linear(n_h, n_out),  # 隐藏层到输出层的线性变换
    nn.Sigmoid()            # 输出层的Sigmoid激活函数，将结果映射到0到1之间，用于二分类任务。
).to(device)

# 定义损失函数和优化器
criterion = torch.nn.MSELoss()  # 均方误差损失函数
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)    # 使用随机梯度下降优化器，学习率为0.01

# 训练模型
for epoch in range(50):  # 训练50轮
    y_pred = model(x)   # 前向传播，计算预测值
    loss = criterion(y_pred, y) # 计算损失
    print('epoch:', epoch + 1, 'loss:', loss.item())    # 打印损失值

    optimizer.zero_grad()   # 清零梯度
    loss.backward()     # 反向传播，计算梯度
    optimizer.step()    # 更新模型参数
